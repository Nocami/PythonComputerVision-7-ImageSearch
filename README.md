# PythonComputerVision-7-ImageSearch
利用文本挖掘技术对基于图像视觉内容进行图像搜索，建立视觉单词（视觉码本）的概念，再建立相应数据库，最终实现在数据库中搜索图像，利用索引获取候选图像，再使用一幅图像进行查询。将上述工作最终建立为相应的演示程序以及web应用。  
## 一.基于内容的图像检索  
在大型图像数据库上，CBIR（Content-Based Image Retrieval基于内容的图像检索），用于检索在视觉上具有相似性的图像，如颜色、纹理、图像中相似的物体或场景等等。  
但是传统的数据库图像匹配时不可行的，因为数据库很大的情况下，利用特征匹配的查询方式会耗费过多的时间。所以我们引入一种模型--矢量空间模型。  
### 1.矢量空间模型  
矢量空间模型时一个用于表示和搜索文本文档的模型，它基本可以应用于任何对象类型，包括图像。这些矢量是由文本词频直方图构成的，换句话说，矢量包含了每个单词出现的次数，
而且在其他别的地方包含很多0元素。由于其忽略了单词出现的顺序及位置，该模型也被称为BOW表示模型。  
通过单词计数来构建文档直方图向量v，从而建立文档索引。通常，数据集中一个单词的重要性与它在文档中出现的次数成正比，而与它在语料库中出现的次数成反比。  
最常用的权重是tf-idf（tern frequency-inverse document frequency，词频-逆向文档频率），单词w在文档d中的词频是:  
![image](01.jpg)  
逆向文件频率 (inverse document frequency, IDF)  IDF的主要思想是：如果包含词条t的文档越少, IDF越大，则说明词条具有很好的类别区分能力。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。  
![image](02.jpg)  
某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。  
![image](03.jpg)   
## 二.视觉单词
将文本挖掘技术应用到图像中，首先需要建立等效视觉单词，可以用之前博文中提到的SIFT局部描述子做到。它的思想是将描述子空间量化成一些典型实例，并将图像中的每个描述子指派到其中的某个实例中。这些典型实例可以通过分析训练图像集确定，并被视为视觉单词。所有这些视觉单词构成的集合称为**视觉词汇**，有时也称为**视觉码本**。  
### 1.BOW模型
从一个很大的训练图像提取特征描述子，利用一些聚类算法可以构建出视觉单词。聚类算法最常用的是**K-means**，这里也采用K-means。视觉单词并不抽象，它只是在给定特殊描述子空间中的一组向量集，在采用K-means进行聚类时得到的视觉单词时聚类质心。用视觉单词直方图来表示图像，则该模型称为BOW模型。这里展示一个示例数据集，用它可以说明BOW概念。文件first1000.zip包含了肯塔基大学物体识别数据集（ukbench）的前1000幅图片，完整数据集及配套代码可以去 http://www.bis.uky.edu/~stewe/ukbench/ 找到。这个数据集有很多子集，每个子集包括四幅图像，具有相同的场景或物体，而且存储的文件名时连续的。如下图所示：  
![image](04.jpg)  
### 2.创建词汇
为创建视觉单词词汇，我们需要提取特征描述子，这里，使用之前博文中介绍过的SIFT特征描述子。imlist包含的是图像的文件名，运行相应的代码（后文给出），可以得到每幅图的描述子，并且将每幅图像的描述子保存在一个文件中。
